\textbf{Входные параметры:}

x --- указатель на исходный массив;
 
VMHL\_N --- размер массива x.

\textbf{Возвращаемое значение:} 
 
Значение тестовой функции в точке x.

\textbf {Описание функции}

\begin{tabularwide}
\textbf{Идентификатор:} & MHL\_TestFunction\_Himmelblau. \\
\textbf{Наименование:} & Функция Химмельблау. \\
\textbf{Тип:} & Задача вещественной оптимизации. \\
\end{tabularwide}

\textbf{Формула} (целевая функция):

\begin{equation}
\label{TestFunctions:eq:MHL_TestFunction_Himmelblau}
f\left( \bar{x}\right) = \left( \bar{x}_1^2+\bar{x}_2-11\right)^2+\left( \bar{x}_1+\bar{x}^2-7\right)^2 , \text{ где}
\end{equation}
\indent $\bar{x}\in X$, $\bar{x}_j\in \left[ Left_j; Right_j\right] $, $Left_j=-5$, $Right_j=5$, $j=\overline{1,n}$, $n=2$.

\begin{tabularwide}
\textbf{Обозначение:} &\specialcell{$\bar{x}$ --- вещественный вектор;\\$n = 2$ --- размерность вещественного вектора.}  \\
\textbf{Решаемая задача оптимизации:} & $\bar{x}_{min}= \arg \min_{\bar{x}\in X} f\left( \bar{x}\right)$.   \\
\textbf{Точки минимума:} & \specialcell{$\bar{x}_{min}^1={\left( 3, 2\right)}^\mathrm{T} $, \\$\bar{x}_{min}^2\approx{\left( -2.8051183, 3.131312\right)}^\mathrm{T} $\\$\bar{x}_{min}^3\approx{\left( -3.779310, -3.283186\right)}^\mathrm{T} $\\$\bar{x}_{min}^4\approx{\left( 3.584428, -1.848126\right)}^\mathrm{T} $.}    \\
\textbf{Минимум функции:} & $f\left(\bar{x}_{min}^i \right) =0$, $i=\overline{1,4}$.   \\
\textbf{График:} & Рисунок \ref{TestFunctions:img:MHL_TestFunction_Himmelblaue} нас \pageref{TestFunctions:img:MHL_TestFunction_Himmelblaue} стр.   \\
\end{tabularwide}

\begin{figure} [h] 
  \center
  \includegraphics [scale=0.5] {MHL_TestFunction_Himmelblau}
  \caption{Функция Химмельблау} 
  \label{TestFunctions:img:MHL_TestFunction_Himmelblaue}  
\end{figure}

\textbf {Параметры для алгоритмов оптимизации}

\begin{tabularwide}
\textbf{Точность вычислений:} & $\varepsilon=0.025$. \\
\textbf{Число интервалов, на которые предполагается разбивать каждую компоненту вектора $\bar{x}$ в пределах своего изменения} (для алгоритмов дискретной оптимизации) : & $NumberOfParts_j=4095$ ($j=\overline{1,n}$). \\
\textbf{Для этого длина бинарной строки для $x_j$ координаты равна} (для алгоритмов бинарной оптимизации) : & $\left( k_2\right)_j=12$ ($j=\overline{1,n}$). \\
\end{tabularwide}

\textbf{Замечание:}  $NumberOfParts_j$ выбирается как минимальное число, удовлетворяющее соотношению:
\begin{equation*}
NumberOfParts_j=2^{\left( k_2\right)_j }-1\geq\dfrac{10\left( Right_j-Left_j\right) }{\varepsilon},\text{где } \left( k_2\right)_j \in \mathbb{N}, \left( j=\overline{1,n}\right).
\end{equation*}

\textbf {Основная задача и подзадачи}

\begin{tabularwide}
\textbf{Изменяемый параметр: } & $n$ --- размерность вещественного вектора. \\
\textbf{Значение в основной задаче:} & $n=2$.\\
\end{tabularwide}

\textbf {Нахождение ошибки оптимизации}

{\color{red} \textbf{Внимание!} В отличии от других функций формулы нахождения ошибок другие, так как есть несколько идентичных по значению целевой функции глобальных минимумов.}

Пусть в результате работы алгоритма оптимизации за $N$ запусков мы нашли решения $\bar{x}_{submin}^k$ со значениями целевой функции $f\left( \bar{x}_{submin}^k\right) $ соответственно ($k=\overline{1,N}$). Используем три вида ошибок:

\textbf{Надёжность: }

\begin{equation*}
R = \dfrac{\sum_{k=1}^{N}S\left( \bar{x}_{submin}^k \right) }{N}, \text{ где}
\end{equation*}
\begin{equation*}
S\left( \bar{x}_{submin}^k \right)=\left\lbrace \begin{aligned} 1,& \text{ если } \left| \left( \bar{x}_{submin}^k \right)_j-\left( \bar{x}_{min}^1 \right)_j\right|<\varepsilon, j=\overline{1,n};   \\ 1,& \text{ если } \left| \left( \bar{x}_{submin}^k \right)_j-\left( \bar{x}_{min}^2 \right)_j\right|<\varepsilon, j=\overline{1,n};   \\ 1,& \text{ если } \left| \left( \bar{x}_{submin}^k \right)_j-\left( \bar{x}_{min}^3 \right)_j\right|<\varepsilon, j=\overline{1,n};   \\ 1,& \text{ если } \left| \left( \bar{x}_{submin}^k \right)_j-\left( \bar{x}_{min}^4 \right)_j\right|<\varepsilon, j=\overline{1,n};   \\ 0,& \text{ иначе}. \end{aligned}\right.
\end{equation*}

\textbf{Ошибка по входным параметрам:}

\begin{equation*}
E_x = \min_{i=\overline{1,4}} \left\lbrace  \frac{\sum_{k=1}^{N} \left( \frac{\sqrt{\sum_{j=1}^{n}{\left( \left( \bar{x}_{submin}^k \right)_j-\left( \bar{x}_{min}^i \right)_j \right)}^2 }}{n} \right)  }{N}\right\rbrace  .
\end{equation*}

\textbf{Ошибка по значениям целевой функции: }
 (без изменений)
\begin{equation*}
E_f = \dfrac{\sum_{k=1}^{N} \left| f\left( \bar{x}_{submin}^k \right)-f\left( \bar{x}_{min} \right) \right|  }{N}.
\end{equation*}

\textbf {Свойства задачи}

\begin{tabularwide}
\textbf{Условной или безусловной оптимизации: } & Задача безусловной оптимизации. \\
\textbf{Одномерной или многомерной оптимизации: } & Многомерной: (двумерной). \\
\textbf{Функция унимодальная или многоэкстремальная: } & Функция многоэкстремальная. \\
\textbf{Функция стохастическая или нет: } & Функция не стохастическая. \\
\textbf{Особенности: } & Есть 4 глобальных минимума. \\
\end{tabularwide}